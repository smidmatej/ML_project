{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load the training data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>attack</th>\n",
       "      <th>last_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "    attack  last_flag  \n",
       "0   normal         20  \n",
       "1   normal         15  \n",
       "2  neptune         19  \n",
       "3   normal         21  \n",
       "4   normal         21  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Check the data consistency</h1>\n",
    "\n",
    "We check the number of duplicates using the pandas <em>duplicated()</em> method. The assertion checks if the number of non-duplicates (unique) rows is equal to the total number of rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_duplicates = df.duplicated().value_counts()\n",
    "assert number_of_duplicates[0] == df.shape[0], 'There are duplicates in the dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the names of the collumns are all unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False] [43]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique, counts = np.unique(df.columns.duplicated(), return_counts=True)\n",
    "print(unique, counts)\n",
    "assert unique[0] == False, 'There are duplicate columns in the dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the categorical column names from the dataframe. Next we will replace their string values by their one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type', 'service', 'flag', 'attack']\n"
     ]
    }
   ],
   "source": [
    "list_of_categorical_columns = [df.columns[i] for i in range(len(df.columns)) if type(df[df.columns[i]][0]) == str]\n",
    "print(list_of_categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['tcp' 'udp' 'tcp' ... 'tcp' 'tcp' 'tcp'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(df[category]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[39m#enc = OneHotEncoder(handle_unknown='error').fit(df[category].to_numpy().reshape(-1,1))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m enc \u001b[39m=\u001b[39m OneHotEncoder(handle_unknown\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(df[category])\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(enc\u001b[39m.\u001b[39mcategories_)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(df[category]\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:818\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39mFit OneHotEncoder to X.\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39m    Fitted encoder.\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_keywords()\n\u001b[0;32m--> 818\u001b[0m fit_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    819\u001b[0m     X,\n\u001b[1;32m    820\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m    821\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    822\u001b[0m     return_counts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infrequent_enabled,\n\u001b[1;32m    823\u001b[0m )\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infrequent_enabled:\n\u001b[1;32m    825\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_infrequent_category_mapping(\n\u001b[1;32m    826\u001b[0m         fit_results[\u001b[39m\"\u001b[39m\u001b[39mn_samples\u001b[39m\u001b[39m\"\u001b[39m], fit_results[\u001b[39m\"\u001b[39m\u001b[39mcategory_counts\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    827\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:80\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(\n\u001b[1;32m     81\u001b[0m     X, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_ \u001b[39m=\u001b[39m n_features\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:45\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mPerform custom check_array:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m- convert list of strings to object dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[39m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     X_temp \u001b[39m=\u001b[39m check_array(X, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite)\n\u001b[1;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(X_temp\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mstr_):\n\u001b[1;32m     47\u001b[0m         X \u001b[39m=\u001b[39m check_array(X, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m, force_all_finite\u001b[39m=\u001b[39mforce_all_finite)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['tcp' 'udp' 'tcp' ... 'tcp' 'tcp' 'tcp'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#print(df[list_of_categorical_columns].to_numpy())\n",
    "for category in list_of_categorical_columns:\n",
    "    print(df[category].shape)\n",
    "    #enc = OneHotEncoder(handle_unknown='error').fit(df[category].to_numpy().reshape(-1,1))\n",
    "    enc = OneHotEncoder(handle_unknown='error').fit(df[category])\n",
    "    \n",
    "    print(enc.categories_)\n",
    "    print(df[category].to_numpy().reshape(-1, 1))\n",
    "    transformed = enc.transform(df[category].to_numpy().reshape(-1, 1))\n",
    "    #Create a Pandas DataFrame of the hot encoded column\n",
    "    print(transformed)\n",
    "    ohe_df = pd.DataFrame({category: transformed})\n",
    "    print(ohe_df)\n",
    "    #concat with original data\n",
    "    #df_onehot = df.drop(category, axis=1)\n",
    "    #df_onehot = pd.concat([df_onehot, ohe_df], axis=1)\n",
    "    #df = pd.concat([df, ohe_df], axis=1).drop([category], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a Pandas DataFrame of the hot encoded column\n",
    "ohe_df = pd.DataFrame(transformed, columns=jobs_encoder.get_feature_names())\n",
    "#concat with original data\n",
    "data = pd.concat([data, ohe_df], axis=1).drop(['Profession'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
